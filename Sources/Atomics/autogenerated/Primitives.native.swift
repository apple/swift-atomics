//===----------------------------------------------------------------------===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2023 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//


// #############################################################################
// #                                                                           #
// #            DO NOT EDIT THIS FILE; IT IS AUTOGENERATED.                    #
// #                                                                           #
// #############################################################################


#if ATOMICS_NATIVE_BUILTINS
import Swift

#if arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32)
@frozen
@_alignment(8)
public struct DoubleWord {
  @usableFromInline
  internal typealias _Builtin = Builtin.Int64

  public var first: UInt
  public var second: UInt

  @inlinable @inline(__always)
  public init(first: UInt, second: UInt) {
    self.first = first
    self.second = second
  }
}
#else
@frozen
@_alignment(16)
public struct DoubleWord {
  @usableFromInline
  internal typealias _Builtin = Builtin.Int128

  public var first: UInt
  public var second: UInt

  @inlinable @inline(__always)
  public init(first: UInt, second: UInt) {
    self.first = first
    self.second = second
  }
}
#endif

extension DoubleWord {
  @_alwaysEmitIntoClient
  @inline(__always)
  internal init(_ builtin: _Builtin) {
    self = unsafeBitCast(builtin, to: DoubleWord.self)
  }

  @_alwaysEmitIntoClient
  @inline(__always)
  internal var _value: _Builtin {
    unsafeBitCast(self, to: _Builtin.self)
  }
}

extension Bool {
  @_alwaysEmitIntoClient
  @inline(__always)
  internal init(_ builtin: Builtin.Int1) {
    self = unsafeBitCast(builtin, to: Bool.self)
  }
}

@_alwaysEmitIntoClient
@_transparent
internal func _atomicMemoryFence(
  ordering: AtomicUpdateOrdering
) {
  switch ordering {
    case .relaxed:
      break
    case .acquiring:
      Builtin.fence_acquire()
    case .releasing:
      Builtin.fence_release()
    case .acquiringAndReleasing:
      Builtin.fence_acqrel()
    case .sequentiallyConsistent:
      Builtin.fence_seqcst()
    default:
      fatalError("Unsupported ordering")
  }
}


extension UnsafeMutablePointer where Pointee == Int8 {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> Int8 {
    switch ordering {
    case .relaxed:
      return Int8(Builtin.atomicload_monotonic_Int8(_rawValue))
    case .acquiring:
      return Int8(Builtin.atomicload_acquire_Int8(_rawValue))
    case .sequentiallyConsistent:
      return Int8(Builtin.atomicload_seqcst_Int8(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: Int8,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int8(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int8(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int8(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: Int8,
    ordering: AtomicUpdateOrdering
  ) -> Int8 {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int8(
        _rawValue, desired._value)
      return Int8(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int8(
        _rawValue, desired._value)
      return Int8(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int8(
        _rawValue, desired._value)
      return Int8(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int8(
        _rawValue, desired._value)
      return Int8(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int8(
        _rawValue, desired._value)
      return Int8(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int8,
    desired: Int8,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Int8) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int8,
    desired: Int8,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int8) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: Int8,
    desired: Int8,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int8) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int8(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int8(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic wrapping add operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&+` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingIncrement(
    by operand: Int8,
    ordering: AtomicUpdateOrdering
  ) -> Int8 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_add_monotonic_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiring:
      let value = Builtin.atomicrmw_add_acquire_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .releasing:
      let value = Builtin.atomicrmw_add_release_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_add_acqrel_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_add_seqcst_Int8(
        _rawValue, operand._value)
      return Int8(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic wrapping subtract operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&-` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingDecrement(
    by operand: Int8,
    ordering: AtomicUpdateOrdering
  ) -> Int8 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_sub_monotonic_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiring:
      let value = Builtin.atomicrmw_sub_acquire_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .releasing:
      let value = Builtin.atomicrmw_sub_release_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_sub_acqrel_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_sub_seqcst_Int8(
        _rawValue, operand._value)
      return Int8(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise AND operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseAnd(
    with operand: Int8,
    ordering: AtomicUpdateOrdering
  ) -> Int8 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_and_monotonic_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiring:
      let value = Builtin.atomicrmw_and_acquire_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .releasing:
      let value = Builtin.atomicrmw_and_release_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_and_acqrel_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_and_seqcst_Int8(
        _rawValue, operand._value)
      return Int8(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise OR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseOr(
    with operand: Int8,
    ordering: AtomicUpdateOrdering
  ) -> Int8 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_or_monotonic_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiring:
      let value = Builtin.atomicrmw_or_acquire_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .releasing:
      let value = Builtin.atomicrmw_or_release_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_or_acqrel_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_or_seqcst_Int8(
        _rawValue, operand._value)
      return Int8(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise XOR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseXor(
    with operand: Int8,
    ordering: AtomicUpdateOrdering
  ) -> Int8 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_xor_monotonic_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiring:
      let value = Builtin.atomicrmw_xor_acquire_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .releasing:
      let value = Builtin.atomicrmw_xor_release_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_xor_acqrel_Int8(
        _rawValue, operand._value)
      return Int8(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_xor_seqcst_Int8(
        _rawValue, operand._value)
      return Int8(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
}


extension UnsafeMutablePointer where Pointee == Int16 {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> Int16 {
    switch ordering {
    case .relaxed:
      return Int16(Builtin.atomicload_monotonic_Int16(_rawValue))
    case .acquiring:
      return Int16(Builtin.atomicload_acquire_Int16(_rawValue))
    case .sequentiallyConsistent:
      return Int16(Builtin.atomicload_seqcst_Int16(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: Int16,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int16(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int16(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int16(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: Int16,
    ordering: AtomicUpdateOrdering
  ) -> Int16 {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int16(
        _rawValue, desired._value)
      return Int16(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int16(
        _rawValue, desired._value)
      return Int16(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int16(
        _rawValue, desired._value)
      return Int16(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int16(
        _rawValue, desired._value)
      return Int16(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int16(
        _rawValue, desired._value)
      return Int16(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int16,
    desired: Int16,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Int16) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int16,
    desired: Int16,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int16) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: Int16,
    desired: Int16,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int16) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int16(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int16(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic wrapping add operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&+` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingIncrement(
    by operand: Int16,
    ordering: AtomicUpdateOrdering
  ) -> Int16 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_add_monotonic_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiring:
      let value = Builtin.atomicrmw_add_acquire_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .releasing:
      let value = Builtin.atomicrmw_add_release_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_add_acqrel_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_add_seqcst_Int16(
        _rawValue, operand._value)
      return Int16(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic wrapping subtract operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&-` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingDecrement(
    by operand: Int16,
    ordering: AtomicUpdateOrdering
  ) -> Int16 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_sub_monotonic_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiring:
      let value = Builtin.atomicrmw_sub_acquire_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .releasing:
      let value = Builtin.atomicrmw_sub_release_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_sub_acqrel_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_sub_seqcst_Int16(
        _rawValue, operand._value)
      return Int16(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise AND operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseAnd(
    with operand: Int16,
    ordering: AtomicUpdateOrdering
  ) -> Int16 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_and_monotonic_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiring:
      let value = Builtin.atomicrmw_and_acquire_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .releasing:
      let value = Builtin.atomicrmw_and_release_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_and_acqrel_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_and_seqcst_Int16(
        _rawValue, operand._value)
      return Int16(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise OR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseOr(
    with operand: Int16,
    ordering: AtomicUpdateOrdering
  ) -> Int16 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_or_monotonic_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiring:
      let value = Builtin.atomicrmw_or_acquire_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .releasing:
      let value = Builtin.atomicrmw_or_release_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_or_acqrel_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_or_seqcst_Int16(
        _rawValue, operand._value)
      return Int16(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise XOR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseXor(
    with operand: Int16,
    ordering: AtomicUpdateOrdering
  ) -> Int16 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_xor_monotonic_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiring:
      let value = Builtin.atomicrmw_xor_acquire_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .releasing:
      let value = Builtin.atomicrmw_xor_release_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_xor_acqrel_Int16(
        _rawValue, operand._value)
      return Int16(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_xor_seqcst_Int16(
        _rawValue, operand._value)
      return Int16(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
}


extension UnsafeMutablePointer where Pointee == Int32 {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> Int32 {
    switch ordering {
    case .relaxed:
      return Int32(Builtin.atomicload_monotonic_Int32(_rawValue))
    case .acquiring:
      return Int32(Builtin.atomicload_acquire_Int32(_rawValue))
    case .sequentiallyConsistent:
      return Int32(Builtin.atomicload_seqcst_Int32(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: Int32,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int32(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int32(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int32(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: Int32,
    ordering: AtomicUpdateOrdering
  ) -> Int32 {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int32(
        _rawValue, desired._value)
      return Int32(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int32(
        _rawValue, desired._value)
      return Int32(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int32(
        _rawValue, desired._value)
      return Int32(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int32(
        _rawValue, desired._value)
      return Int32(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int32(
        _rawValue, desired._value)
      return Int32(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int32,
    desired: Int32,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Int32) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int32,
    desired: Int32,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int32) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: Int32,
    desired: Int32,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int32) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int32(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic wrapping add operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&+` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingIncrement(
    by operand: Int32,
    ordering: AtomicUpdateOrdering
  ) -> Int32 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_add_monotonic_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiring:
      let value = Builtin.atomicrmw_add_acquire_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .releasing:
      let value = Builtin.atomicrmw_add_release_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_add_acqrel_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_add_seqcst_Int32(
        _rawValue, operand._value)
      return Int32(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic wrapping subtract operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&-` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingDecrement(
    by operand: Int32,
    ordering: AtomicUpdateOrdering
  ) -> Int32 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_sub_monotonic_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiring:
      let value = Builtin.atomicrmw_sub_acquire_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .releasing:
      let value = Builtin.atomicrmw_sub_release_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_sub_acqrel_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_sub_seqcst_Int32(
        _rawValue, operand._value)
      return Int32(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise AND operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseAnd(
    with operand: Int32,
    ordering: AtomicUpdateOrdering
  ) -> Int32 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_and_monotonic_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiring:
      let value = Builtin.atomicrmw_and_acquire_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .releasing:
      let value = Builtin.atomicrmw_and_release_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_and_acqrel_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_and_seqcst_Int32(
        _rawValue, operand._value)
      return Int32(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise OR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseOr(
    with operand: Int32,
    ordering: AtomicUpdateOrdering
  ) -> Int32 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_or_monotonic_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiring:
      let value = Builtin.atomicrmw_or_acquire_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .releasing:
      let value = Builtin.atomicrmw_or_release_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_or_acqrel_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_or_seqcst_Int32(
        _rawValue, operand._value)
      return Int32(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise XOR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseXor(
    with operand: Int32,
    ordering: AtomicUpdateOrdering
  ) -> Int32 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_xor_monotonic_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiring:
      let value = Builtin.atomicrmw_xor_acquire_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .releasing:
      let value = Builtin.atomicrmw_xor_release_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_xor_acqrel_Int32(
        _rawValue, operand._value)
      return Int32(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_xor_seqcst_Int32(
        _rawValue, operand._value)
      return Int32(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
}


extension UnsafeMutablePointer where Pointee == Int64 {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> Int64 {
    switch ordering {
    case .relaxed:
      return Int64(Builtin.atomicload_monotonic_Int64(_rawValue))
    case .acquiring:
      return Int64(Builtin.atomicload_acquire_Int64(_rawValue))
    case .sequentiallyConsistent:
      return Int64(Builtin.atomicload_seqcst_Int64(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: Int64,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int64(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int64(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int64(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: Int64,
    ordering: AtomicUpdateOrdering
  ) -> Int64 {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int64(
        _rawValue, desired._value)
      return Int64(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int64(
        _rawValue, desired._value)
      return Int64(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int64(
        _rawValue, desired._value)
      return Int64(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int64(
        _rawValue, desired._value)
      return Int64(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int64(
        _rawValue, desired._value)
      return Int64(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int64,
    desired: Int64,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Int64) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int64,
    desired: Int64,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int64) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: Int64,
    desired: Int64,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int64) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int64(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic wrapping add operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&+` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingIncrement(
    by operand: Int64,
    ordering: AtomicUpdateOrdering
  ) -> Int64 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_add_monotonic_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiring:
      let value = Builtin.atomicrmw_add_acquire_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .releasing:
      let value = Builtin.atomicrmw_add_release_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_add_acqrel_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_add_seqcst_Int64(
        _rawValue, operand._value)
      return Int64(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic wrapping subtract operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&-` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingDecrement(
    by operand: Int64,
    ordering: AtomicUpdateOrdering
  ) -> Int64 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_sub_monotonic_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiring:
      let value = Builtin.atomicrmw_sub_acquire_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .releasing:
      let value = Builtin.atomicrmw_sub_release_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_sub_acqrel_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_sub_seqcst_Int64(
        _rawValue, operand._value)
      return Int64(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise AND operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseAnd(
    with operand: Int64,
    ordering: AtomicUpdateOrdering
  ) -> Int64 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_and_monotonic_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiring:
      let value = Builtin.atomicrmw_and_acquire_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .releasing:
      let value = Builtin.atomicrmw_and_release_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_and_acqrel_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_and_seqcst_Int64(
        _rawValue, operand._value)
      return Int64(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise OR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseOr(
    with operand: Int64,
    ordering: AtomicUpdateOrdering
  ) -> Int64 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_or_monotonic_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiring:
      let value = Builtin.atomicrmw_or_acquire_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .releasing:
      let value = Builtin.atomicrmw_or_release_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_or_acqrel_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_or_seqcst_Int64(
        _rawValue, operand._value)
      return Int64(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise XOR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseXor(
    with operand: Int64,
    ordering: AtomicUpdateOrdering
  ) -> Int64 {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_xor_monotonic_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiring:
      let value = Builtin.atomicrmw_xor_acquire_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .releasing:
      let value = Builtin.atomicrmw_xor_release_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_xor_acqrel_Int64(
        _rawValue, operand._value)
      return Int64(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_xor_seqcst_Int64(
        _rawValue, operand._value)
      return Int64(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
}

#if arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32)
extension UnsafeMutablePointer where Pointee == Int {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> Int {
    switch ordering {
    case .relaxed:
      return Int(Builtin.atomicload_monotonic_Int32(_rawValue))
    case .acquiring:
      return Int(Builtin.atomicload_acquire_Int32(_rawValue))
    case .sequentiallyConsistent:
      return Int(Builtin.atomicload_seqcst_Int32(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: Int,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int32(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int32(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int32(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int32(
        _rawValue, desired._value)
      return Int(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int32(
        _rawValue, desired._value)
      return Int(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int32(
        _rawValue, desired._value)
      return Int(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int32(
        _rawValue, desired._value)
      return Int(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int32(
        _rawValue, desired._value)
      return Int(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int,
    desired: Int,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Int) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int,
    desired: Int,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: Int,
    desired: Int,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int32(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic wrapping add operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&+` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingIncrement(
    by operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_add_monotonic_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_add_acquire_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_add_release_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_add_acqrel_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_add_seqcst_Int32(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic wrapping subtract operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&-` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingDecrement(
    by operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_sub_monotonic_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_sub_acquire_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_sub_release_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_sub_acqrel_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_sub_seqcst_Int32(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise AND operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseAnd(
    with operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_and_monotonic_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_and_acquire_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_and_release_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_and_acqrel_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_and_seqcst_Int32(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise OR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseOr(
    with operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_or_monotonic_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_or_acquire_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_or_release_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_or_acqrel_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_or_seqcst_Int32(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise XOR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseXor(
    with operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_xor_monotonic_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_xor_acquire_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_xor_release_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_xor_acqrel_Int32(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_xor_seqcst_Int32(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
}

#else /* arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32) */
extension UnsafeMutablePointer where Pointee == Int {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> Int {
    switch ordering {
    case .relaxed:
      return Int(Builtin.atomicload_monotonic_Int64(_rawValue))
    case .acquiring:
      return Int(Builtin.atomicload_acquire_Int64(_rawValue))
    case .sequentiallyConsistent:
      return Int(Builtin.atomicload_seqcst_Int64(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: Int,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int64(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int64(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int64(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int64(
        _rawValue, desired._value)
      return Int(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int64(
        _rawValue, desired._value)
      return Int(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int64(
        _rawValue, desired._value)
      return Int(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int64(
        _rawValue, desired._value)
      return Int(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int64(
        _rawValue, desired._value)
      return Int(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int,
    desired: Int,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Int) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: Int,
    desired: Int,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: Int,
    desired: Int,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Int) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), Int(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic wrapping add operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&+` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingIncrement(
    by operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_add_monotonic_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_add_acquire_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_add_release_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_add_acqrel_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_add_seqcst_Int64(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic wrapping subtract operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Note: This operation silently wraps around on overflow, like the
  /// `&-` operator does on `UInt` values.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenWrappingDecrement(
    by operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_sub_monotonic_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_sub_acquire_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_sub_release_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_sub_acqrel_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_sub_seqcst_Int64(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise AND operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseAnd(
    with operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_and_monotonic_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_and_acquire_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_and_release_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_and_acqrel_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_and_seqcst_Int64(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise OR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseOr(
    with operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_or_monotonic_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_or_acquire_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_or_release_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_or_acqrel_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_or_seqcst_Int64(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
  /// Perform an atomic bitwise XOR operation and return the new value,
  /// with the specified memory ordering.
  ///
  /// - Returns: The original value before the operation.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal
  func _atomicLoadThenBitwiseXor(
    with operand: Int,
    ordering: AtomicUpdateOrdering
  ) -> Int {
    switch ordering {
    case .relaxed:
      let value = Builtin.atomicrmw_xor_monotonic_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiring:
      let value = Builtin.atomicrmw_xor_acquire_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .releasing:
      let value = Builtin.atomicrmw_xor_release_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .acquiringAndReleasing:
      let value = Builtin.atomicrmw_xor_acqrel_Int64(
        _rawValue, operand._value)
      return Int(value)
    case .sequentiallyConsistent:
      let value = Builtin.atomicrmw_xor_seqcst_Int64(
        _rawValue, operand._value)
      return Int(value)
    default:
      preconditionFailure("Unsupported ordering")
    }
  }
}
#endif /* arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32) */
#if arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32)
extension UnsafeMutablePointer where Pointee == DoubleWord {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> DoubleWord {
    switch ordering {
    case .relaxed:
      return DoubleWord(Builtin.atomicload_monotonic_Int64(_rawValue))
    case .acquiring:
      return DoubleWord(Builtin.atomicload_acquire_Int64(_rawValue))
    case .sequentiallyConsistent:
      return DoubleWord(Builtin.atomicload_seqcst_Int64(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: DoubleWord,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int64(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int64(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int64(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: DoubleWord,
    ordering: AtomicUpdateOrdering
  ) -> DoubleWord {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int64(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int64(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int64(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int64(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int64(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: DoubleWord,
    desired: DoubleWord,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: DoubleWord) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: DoubleWord,
    desired: DoubleWord,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: DoubleWord) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: DoubleWord,
    desired: DoubleWord,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: DoubleWord) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int64(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

}

#else /* arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32) */
extension UnsafeMutablePointer where Pointee == DoubleWord {
  /// Atomically loads a word starting at this address with the specified
  /// memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicLoad(ordering: AtomicLoadOrdering) -> DoubleWord {
    switch ordering {
    case .relaxed:
      return DoubleWord(Builtin.atomicload_monotonic_Int128(_rawValue))
    case .acquiring:
      return DoubleWord(Builtin.atomicload_acquire_Int128(_rawValue))
    case .sequentiallyConsistent:
      return DoubleWord(Builtin.atomicload_seqcst_Int128(_rawValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  @usableFromInline
  internal func _atomicStore(
    _ desired: DoubleWord,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      Builtin.atomicstore_monotonic_Int128(_rawValue, desired._value)
    case .releasing:
      Builtin.atomicstore_release_Int128(_rawValue, desired._value)
    case .sequentiallyConsistent:
      Builtin.atomicstore_seqcst_Int128(_rawValue, desired._value)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Atomically stores the specified value starting at the memory referenced by
  /// this pointer, with the specified memory ordering.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicExchange(
    _ desired: DoubleWord,
    ordering: AtomicUpdateOrdering
  ) -> DoubleWord {
    switch ordering {
    case .relaxed:
      let oldValue = Builtin.atomicrmw_xchg_monotonic_Int128(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .acquiring:
      let oldValue = Builtin.atomicrmw_xchg_acquire_Int128(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .releasing:
      let oldValue = Builtin.atomicrmw_xchg_release_Int128(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .acquiringAndReleasing:
      let oldValue = Builtin.atomicrmw_xchg_acqrel_Int128(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    case .sequentiallyConsistent:
      let oldValue = Builtin.atomicrmw_xchg_seqcst_Int128(
        _rawValue, desired._value)
      return DoubleWord(oldValue)
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified memory
  /// ordering.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: DoubleWord,
    desired: DoubleWord,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: DoubleWord) {
    switch ordering {
    case .relaxed:
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .acquiring:
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .releasing:
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .acquiringAndReleasing:
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case .sequentiallyConsistent:
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    default:
      fatalError("Unsupported ordering")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicCompareExchange(
    expected: DoubleWord,
    desired: DoubleWord,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: DoubleWord) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

  /// Perform an atomic compare and exchange operation with the specified
  /// success/failure memory orderings.
  ///
  /// This operation is equivalent to the following pseudocode:
  ///
  /// ```
  /// atomic(self, ordering, failureOrdering) { currentValue in
  ///   let original = currentValue
  ///   guard original == expected else { return (false, original) }
  ///   currentValue = desired
  ///   return (true, original)
  /// }
  /// ```
  ///
  /// The `ordering` argument specifies the memory ordering to use when the
  /// operation manages to update the current value, while `failureOrdering`
  /// will be used when the operation leaves the value intact.
  @_semantics("atomics.requires_constant_orderings")
  @_alwaysEmitIntoClient
  @_transparent // Debug performance
  public func _atomicWeakCompareExchange(
    expected: DoubleWord,
    desired: DoubleWord,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: DoubleWord) {
    // FIXME: LLVM doesn't support arbitrary ordering combinations
    // yet, so upgrade the success ordering when necessary so that it
    // is at least as "strong" as the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_monotonic_monotonic_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.relaxed, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acquire_monotonic_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acquire_acquire_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiring, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_release_monotonic_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.releasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_monotonic_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_acqrel_acquire_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .relaxed):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_monotonic_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .acquiring):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_acquire_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      let (oldValue, won) = Builtin.cmpxchg_seqcst_seqcst_weak_Int128(
        _rawValue, expected._value, desired._value)
      return (Bool(won), DoubleWord(oldValue))
    default:
      preconditionFailure("Unsupported orderings")
    }
  }

}
#endif /* arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32) */
#endif // ATOMICS_NATIVE_BUILTINS
